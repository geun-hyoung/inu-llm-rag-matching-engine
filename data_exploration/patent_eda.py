"""
íŠ¹í—ˆ ë°ì´í„° íƒìƒ‰ì  ë¶„ì„ (EDA)
êµìˆ˜ì™€ íŠ¹í—ˆì˜ ê´€ê³„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
import sys
from typing import Dict, Any, List
from collections import Counter, defaultdict
import matplotlib.pyplot as plt
import seaborn as sns

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))
from config.settings import PATENT_DATA_FILE, EDA_RESULTS_DIR

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
sns.set_style("whitegrid")
sns.set_palette("husl")


def load_patent_data(file_path: str) -> List[Dict]:
    """íŠ¹í—ˆ JSON ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data):,}ê°œ")
        return data
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return []
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return []


def analyze_basic_info(data: List[Dict]) -> Dict[str, Any]:
    """ê¸°ë³¸ ì •ë³´ ë¶„ì„"""
    if not data:
        return {}
    
    return {
        "total_patents": len(data),
        "total_fields": len(data[0].keys()) if data else 0,
        "field_names": list(data[0].keys()) if data else [],
        "sample_record_keys": list(data[0].keys())[:10] if data else []
    }


def analyze_professor_patent_relationship(data: List[Dict]) -> Dict[str, Any]:
    """êµìˆ˜-íŠ¹í—ˆ ê´€ê³„ ë¶„ì„"""
    if not data:
        return {}
    
    # êµìˆ˜ë³„ íŠ¹í—ˆ ê°œìˆ˜
    professor_patent_count = defaultdict(int)
    professor_info_map = {}
    
    # êµìˆ˜ ì •ë³´ë³„ í†µê³„
    professors_by_college = defaultdict(set)  # ëŒ€í•™ë³„ êµìˆ˜ ì§‘í•©
    professors_by_department = defaultdict(set)  # í•™ê³¼ë³„ êµìˆ˜ ì§‘í•©
    professors_by_status = defaultdict(set)  # ì¬ì§ ìƒíƒœë³„ êµìˆ˜ ì§‘í•©
    
    for item in data:
        prof_info = item.get("professor_info", {})
        if not prof_info:
            continue
        
        # êµìˆ˜ ì‹ë³„ì (SQ ë˜ëŠ” EMP_NO)
        prof_id = prof_info.get("SQ") or prof_info.get("EMP_NO", "")
        if prof_id:
            professor_patent_count[prof_id] += 1
            professor_info_map[prof_id] = prof_info
        
        # ëŒ€í•™/í•™ê³¼/ì¬ì§ ìƒíƒœë³„ ì§‘ê³„
        college = prof_info.get("COLG_NM", "")
        department = prof_info.get("HG_NM", "")
        status = prof_info.get("HOOF_GBN", "")
        
        if prof_id:
            if college:
                professors_by_college[college].add(prof_id)
            if department:
                professors_by_department[department].add(prof_id)
            if status:
                professors_by_status[status].add(prof_id)
    
    # êµìˆ˜ë³„ íŠ¹í—ˆ ê°œìˆ˜ ë¶„í¬
    patent_counts = list(professor_patent_count.values())
    
    return {
        "total_professors": len(professor_patent_count),
        "total_patents": sum(professor_patent_count.values()),
        "professor_patent_distribution": {
            "min": min(patent_counts) if patent_counts else 0,
            "max": max(patent_counts) if patent_counts else 0,
            "mean": sum(patent_counts) / len(patent_counts) if patent_counts else 0,
            "median": sorted(patent_counts)[len(patent_counts)//2] if patent_counts else 0
        },
        "professors_by_patent_count": {
            "1ê°œ": sum(1 for c in patent_counts if c == 1),
            "2-5ê°œ": sum(1 for c in patent_counts if 2 <= c <= 5),
            "6-10ê°œ": sum(1 for c in patent_counts if 6 <= c <= 10),
            "11-20ê°œ": sum(1 for c in patent_counts if 11 <= c <= 20),
            "21ê°œ ì´ìƒ": sum(1 for c in patent_counts if c >= 21)
        },
        "college_distribution": {college: len(profs) for college, profs in professors_by_college.items()},
        "department_distribution": {dept: len(profs) for dept, profs in professors_by_department.items()},
        "status_distribution": {status: len(profs) for status, profs in professors_by_status.items()}
    }


def analyze_patent_status_by_professor(data: List[Dict]) -> Dict[str, Any]:
    """êµìˆ˜ë³„ íŠ¹í—ˆ ìƒíƒœ ë¶„ì„"""
    if not data:
        return {}
    
    # êµìˆ˜ë³„ ìƒíƒœ ë¶„í¬
    professor_status = defaultdict(lambda: defaultdict(int))
    status_overall = defaultdict(int)
    
    for item in data:
        prof_info = item.get("professor_info", {})
        status = item.get("kipris_register_status", "")
        
        if not prof_info or not status:
            continue
        
        prof_id = prof_info.get("SQ") or prof_info.get("EMP_NO", "")
        if prof_id:
            professor_status[prof_id][status] += 1
            status_overall[status] += 1
    
    # êµìˆ˜ë³„ ì£¼ìš” ìƒíƒœ (ê°€ì¥ ë§ì€ ìƒíƒœ)
    professor_main_status = {}
    for prof_id, statuses in professor_status.items():
        if statuses:
            main_status = max(statuses.items(), key=lambda x: x[1])[0]
            professor_main_status[prof_id] = main_status
    
    main_status_distribution = Counter(professor_main_status.values())
    
    return {
        "overall_status_distribution": dict(status_overall),
        "professors_by_main_status": dict(main_status_distribution),
        "status_types": list(status_overall.keys())
    }


def analyze_patent_timeline(data: List[Dict]) -> Dict[str, Any]:
    """íŠ¹í—ˆ ì¶œì› ì‹œê¸° ë¶„ì„ (ì—°ë„ë³„, êµìˆ˜ë³„)"""
    if not data:
        return {}
    
    # ì—°ë„ë³„ ì¶œì› ê°œìˆ˜
    year_patents = defaultdict(int)
    year_professors = defaultdict(set)
    
    # êµìˆ˜ë³„ ì¶œì› ì—°ë„
    professor_years = defaultdict(set)
    
    for item in data:
        date_str = item.get("kipris_application_date", "")
        prof_info = item.get("professor_info", {})
        
        if not date_str or len(date_str) < 4:
            continue
        
        year = date_str[:4]
        year_patents[year] += 1
        
        prof_id = prof_info.get("SQ") or prof_info.get("EMP_NO", "") if prof_info else ""
        if prof_id:
            year_professors[year].add(prof_id)
            professor_years[prof_id].add(year)
    
    # êµìˆ˜ë³„ í™œë™ ê¸°ê°„ (ì¶œì› ì—°ë„ ë²”ìœ„)
    professor_activity_periods = {}
    for prof_id, years in professor_years.items():
        if years:
            year_list = sorted([int(y) for y in years])
            professor_activity_periods[prof_id] = {
                "start_year": min(year_list),
                "end_year": max(year_list),
                "span_years": max(year_list) - min(year_list) + 1,
                "total_years": len(years)
            }
    
    return {
        "year_distribution": dict(sorted(year_patents.items())),
        "professors_per_year": {year: len(profs) for year, profs in sorted(year_professors.items())},
        "activity_period_stats": {
            "avg_span": sum(p["span_years"] for p in professor_activity_periods.values()) / len(professor_activity_periods) if professor_activity_periods else 0,
            "max_span": max((p["span_years"] for p in professor_activity_periods.values()), default=0),
            "min_span": min((p["span_years"] for p in professor_activity_periods.values()), default=0)
        }
    }


def analyze_patent_content(data: List[Dict]) -> Dict[str, Any]:
    """íŠ¹í—ˆ ë‚´ìš© ë¶„ì„ (ì œëª©, ìš”ì•½)"""
    if not data:
        return {}
    
    titles = []
    abstracts = []
    
    for item in data:
        title = item.get("kipris_application_name", "")
        abstract = item.get("kipris_abstract", "")
        
        if title:
            titles.append(title)
        if abstract:
            abstracts.append(abstract)
    
    # ê¸¸ì´ ë¶„ì„
    title_lengths = [len(t) for t in titles]
    abstract_lengths = [len(a) for a in abstracts]
    
    return {
        "titles": {
            "total": len(titles),
            "length_stats": {
                "min": min(title_lengths) if title_lengths else 0,
                "max": max(title_lengths) if title_lengths else 0,
                "mean": sum(title_lengths) / len(title_lengths) if title_lengths else 0,
                "median": sorted(title_lengths)[len(title_lengths)//2] if title_lengths else 0
            }
        },
        "abstracts": {
            "total": len(abstracts),
            "length_stats": {
                "min": min(abstract_lengths) if abstract_lengths else 0,
                "max": max(abstract_lengths) if abstract_lengths else 0,
                "mean": sum(abstract_lengths) / len(abstract_lengths) if abstract_lengths else 0,
                "median": sorted(abstract_lengths)[len(abstract_lengths)//2] if abstract_lengths else 0
            }
        },
        "content_completeness": {
            "has_title": len(titles),
            "has_abstract": len(abstracts),
            "has_both": sum(1 for item in data if item.get("kipris_application_name") and item.get("kipris_abstract"))
        }
    }


def analyze_abstract_detailed(data: List[Dict]) -> Dict[str, Any]:
    """ì´ˆë¡(kipris_abstract)ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„"""
    if not data:
        return {}
    
    abstracts = []
    abstract_lengths = []
    
    for item in data:
        abstract = item.get("kipris_abstract", "")
        if abstract and abstract.strip():  # ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ
            abstracts.append(abstract)
            abstract_lengths.append(len(abstract))
    
    total_items = len(data)
    missing_count = total_items - len(abstracts)
    missing_rate = (missing_count / total_items * 100) if total_items > 0 else 0
    
    if not abstract_lengths:
        return {
            "total_items": total_items,
            "missing_count": missing_count,
            "missing_rate": missing_rate,
            "error": "ì´ˆë¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
    
    # ê¸°ìˆ  í†µê³„ëŸ‰ ê³„ì‚°
    lengths_array = np.array(abstract_lengths)
    
    # 4ë¶„ìœ„ìˆ˜ ê³„ì‚°
    q1 = np.percentile(lengths_array, 25)
    q2 = np.percentile(lengths_array, 50)  # ì¤‘ì•™ê°’
    q3 = np.percentile(lengths_array, 75)
    iqr = q3 - q1  # ì‚¬ë¶„ìœ„ ë²”ìœ„
    
    # ê¸°ìˆ  í†µê³„ëŸ‰
    mean_length = np.mean(lengths_array)
    median_length = np.median(lengths_array)
    std_length = np.std(lengths_array)
    min_length = np.min(lengths_array)
    max_length = np.max(lengths_array)
    
    # ë¶„ìœ„ìˆ˜ë³„ ê°œìˆ˜
    q1_count = np.sum(lengths_array <= q1)
    q2_count = np.sum(lengths_array <= q2)
    q3_count = np.sum(lengths_array <= q3)
    
    return {
        "total_items": total_items,
        "missing_count": missing_count,
        "missing_rate": round(missing_rate, 2),
        "valid_count": len(abstracts),
        "valid_rate": round((len(abstracts) / total_items * 100) if total_items > 0 else 0, 2),
        "descriptive_statistics": {
            "min": int(min_length),
            "max": int(max_length),
            "mean": round(mean_length, 2),
            "median": int(median_length),
            "std": round(std_length, 2),
            "q1": int(q1),
            "q2": int(q2),
            "q3": int(q3),
            "iqr": int(iqr)
        },
        "quartile_distribution": {
            "q1_under": int(q1_count),
            "q1_to_q2": int(np.sum((lengths_array > q1) & (lengths_array <= q2))),
            "q2_to_q3": int(np.sum((lengths_array > q2) & (lengths_array <= q3))),
            "q3_over": int(np.sum(lengths_array > q3))
        },
        "length_summary": {
            "shortest": min(abstract_lengths),
            "longest": max(abstract_lengths),
            "shortest_text": abstracts[np.argmin(abstract_lengths)][:100] + "..." if abstracts else "",
            "longest_text": abstracts[np.argmax(abstract_lengths)][:100] + "..." if abstracts else ""
        }
    }


def visualize_abstract_distribution(data: List[Dict], output_dir: Path):
    """ì´ˆë¡ ê¸¸ì´ ë¶„í¬ ì‹œê°í™” - ê°„ë‹¨í•˜ê³  íŠ¸ë Œë“œí•œ í•™ìˆ ì  ìŠ¤íƒ€ì¼"""
    if not data:
        return
    
    abstract_lengths = []
    for item in data:
        abstract = item.get("kipris_abstract", "")
        if abstract and abstract.strip():
            abstract_lengths.append(len(abstract))
    
    if not abstract_lengths:
        print("âš ï¸ ì‹œê°í™”í•  ì´ˆë¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ê¹”ë”í•œ ë‹¨ì¼ íˆìŠ¤í† ê·¸ë¨ (í•™ìˆ ì ì´ê³  íŠ¸ë Œë“œí•œ ìŠ¤íƒ€ì¼)
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # íˆìŠ¤í† ê·¸ë¨ (KDE í¬í•¨) - seaborn ìŠ¤íƒ€ì¼
    sns.histplot(abstract_lengths, bins=40, kde=True, 
                 color='#3498db', alpha=0.7, 
                 edgecolor='white', linewidth=0.5)
    
    # í†µê³„ ì„  í‘œì‹œ
    mean_val = np.mean(abstract_lengths)
    median_val = np.median(abstract_lengths)
    q1_val = np.percentile(abstract_lengths, 25)
    q3_val = np.percentile(abstract_lengths, 75)
    
    ax.axvline(mean_val, color='#e74c3c', linestyle='--', linewidth=2, 
               label=f'Mean: {mean_val:.0f}', zorder=5)
    ax.axvline(median_val, color='#2ecc71', linestyle='--', linewidth=2, 
               label=f'Median: {median_val:.0f}', zorder=5)
    
    # ìŠ¤íƒ€ì¼ë§ - í•™ìˆ ì ì´ê³  íŠ¸ë Œë“œí•œ ëŠë‚Œ
    ax.set_xlabel('Abstract Length (characters)', fontsize=13, fontweight='bold')
    ax.set_ylabel('Frequency', fontsize=13, fontweight='bold')
    ax.set_title('Distribution of Patent Abstract Lengths', 
                 fontsize=15, fontweight='bold', pad=20)
    
    # ê·¸ë¦¬ë“œ (ì€ì€í•˜ê²Œ)
    ax.grid(True, alpha=0.2, linestyle='-', linewidth=0.5)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_color('#cccccc')
    ax.spines['bottom'].set_color('#cccccc')
    
    # ë²”ë¡€
    ax.legend(loc='upper right', frameon=True, fancybox=True, 
              shadow=True, fontsize=10)
    
    # í†µê³„ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ê°„ë‹¨íˆ ì¶”ê°€ (í•˜ë‹¨ì—)
    stats_text = f'n = {len(abstract_lengths):,} | ' \
                 f'Q1: {q1_val:.0f} | Q3: {q3_val:.0f} | ' \
                 f'SD: {np.std(abstract_lengths):.1f}'
    ax.text(0.5, 0.02, stats_text, transform=ax.transAxes, 
            ha='center', va='bottom', fontsize=9, 
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='none'),
            style='italic')
    
    plt.tight_layout()
    output_path = output_dir / "abstract_length_distribution.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"âœ… ì´ˆë¡ ë¶„í¬ ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {output_path}")


def analyze_professor_info_completeness(data: List[Dict]) -> Dict[str, Any]:
    """êµìˆ˜ ì •ë³´ ì™„ì „ì„± ë¶„ì„"""
    if not data:
        return {}
    
    prof_fields = ["SQ", "EMP_NO", "NM", "GEN_GBN", "BIRTH_DT", "NAT_GBN", 
                   "RECHER_REG_NO", "WKGD_NM", "COLG_NM", "HG_NM", 
                   "HOOF_GBN", "HANDP_NO", "OFCE_TELNO", "EMAIL"]
    
    field_completeness = defaultdict(int)
    total_with_prof = 0
    
    for item in data:
        prof_info = item.get("professor_info", {})
        if not prof_info:
            continue
        
        total_with_prof += 1
        for field in prof_fields:
            if prof_info.get(field):
                field_completeness[field] += 1
    
    completeness_rate = {
        field: (count / total_with_prof * 100) if total_with_prof > 0 else 0
        for field, count in field_completeness.items()
    }
    
    return {
        "total_with_professor_info": total_with_prof,
        "field_completeness_rate": dict(sorted(completeness_rate.items(), key=lambda x: x[1], reverse=True)),
        "most_complete_fields": list(sorted(completeness_rate.items(), key=lambda x: x[1], reverse=True))[:5],
        "least_complete_fields": list(sorted(completeness_rate.items(), key=lambda x: x[1]))[:5]
    }


def analyze_college_department_patents(data: List[Dict]) -> Dict[str, Any]:
    """ëŒ€í•™/í•™ê³¼ë³„ íŠ¹í—ˆ ë¶„ì„ (êµìˆ˜-íŠ¹í—ˆ ë§¤í•‘ ì¤‘ì‹¬)"""
    if not data:
        return {}
    
    college_patents = defaultdict(int)
    department_patents = defaultdict(int)
    college_department = defaultdict(lambda: defaultdict(int))
    college_professors = defaultdict(set)  # ë‹¨ê³¼ëŒ€ë³„ êµìˆ˜ ì§‘í•©
    department_professors = defaultdict(set)  # í•™ê³¼ë³„ êµìˆ˜ ì§‘í•©
    college_professor_patent_count = defaultdict(lambda: defaultdict(int))  # ë‹¨ê³¼ëŒ€ë³„ êµìˆ˜ë³„ íŠ¹í—ˆìˆ˜
    
    for item in data:
        prof_info = item.get("professor_info", {})
        if not prof_info:
            continue
        
        college = prof_info.get("COLG_NM", "")
        department = prof_info.get("HG_NM", "")
        prof_id = prof_info.get("SQ") or prof_info.get("EMP_NO", "")
        
        if college:
            college_patents[college] += 1
            if prof_id:
                college_professors[college].add(prof_id)
                college_professor_patent_count[college][prof_id] += 1
        
        if department:
            department_patents[department] += 1
            if prof_id:
                department_professors[department].add(prof_id)
        
        if college and department:
            college_department[college][department] += 1
    
    # ë‹¨ê³¼ëŒ€ë³„ í‰ê·  íŠ¹í—ˆ ìˆ˜ (êµìˆ˜ë‹¹)
    college_avg_patents = {}
    for college, prof_patents in college_professor_patent_count.items():
        prof_count = len(prof_patents)
        if prof_count > 0:
            avg_patents = sum(prof_patents.values()) / prof_count
            college_avg_patents[college] = round(avg_patents, 2)
    
    # ë‹¨ê³¼ëŒ€ë³„ êµìˆ˜ë‹¹ í‰ê·  íŠ¹í—ˆìˆ˜ ìˆœìœ„
    top_colleges_by_avg = sorted(college_avg_patents.items(), key=lambda x: x[1], reverse=True)[:10]
    
    return {
        "college_patent_distribution": dict(sorted(college_patents.items(), key=lambda x: x[1], reverse=True)),
        "department_patent_distribution": dict(sorted(department_patents.items(), key=lambda x: x[1], reverse=True)),
        "top_colleges": list(sorted(college_patents.items(), key=lambda x: x[1], reverse=True))[:10],
        "top_departments": list(sorted(department_patents.items(), key=lambda x: x[1], reverse=True))[:10],
        "college_professor_count": {college: len(profs) for college, profs in college_professors.items()},
        "department_professor_count": {dept: len(profs) for dept, profs in department_professors.items()},
        "college_avg_patents_per_professor": college_avg_patents,
        "top_colleges_by_avg_patents": top_colleges_by_avg,
        "college_department_matrix": {
            college: dict(depts) 
            for college, depts in college_department.items()
        }
    }


def save_results(results: Dict[str, Any], output_path: Path):
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")


def print_summary(results: Dict[str, Any]):
    """ìš”ì•½ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("\n" + "=" * 70)
    print("ğŸ“Š íŠ¹í—ˆ ë°ì´í„° EDA ìš”ì•½ - êµìˆ˜ì™€ íŠ¹í—ˆ ê´€ê³„ ì¤‘ì‹¬")
    print("=" * 70)
    
    # ê¸°ë³¸ ì •ë³´
    if "basic_info" in results:
        basic = results["basic_info"]
        print(f"\n1ï¸âƒ£  ê¸°ë³¸ ì •ë³´")
        print(f"   - ì´ íŠ¹í—ˆ ê°œìˆ˜: {basic.get('total_patents', 0):,}ê°œ")
        print(f"   - í•„ë“œ ìˆ˜: {basic.get('total_fields', 0)}ê°œ")
    
    # êµìˆ˜-íŠ¹í—ˆ ê´€ê³„
    if "professor_patent_relationship" in results:
        rel = results["professor_patent_relationship"]
        print(f"\n2ï¸âƒ£  êµìˆ˜-íŠ¹í—ˆ ê´€ê³„")
        print(f"   - ì´ êµìˆ˜ ìˆ˜: {rel.get('total_professors', 0):,}ëª…")
        print(f"   - ì´ íŠ¹í—ˆ ìˆ˜: {rel.get('total_patents', 0):,}ê°œ")
        
        dist = rel.get("professor_patent_distribution", {})
        print(f"   - êµìˆ˜ë‹¹ í‰ê·  íŠ¹í—ˆ ìˆ˜: {dist.get('mean', 0):.2f}ê°œ")
        print(f"   - êµìˆ˜ë‹¹ ì¤‘ì•™ê°’ íŠ¹í—ˆ ìˆ˜: {dist.get('median', 0)}ê°œ")
        print(f"   - ìµœë‹¤ íŠ¹í—ˆ ë³´ìœ  êµìˆ˜: {dist.get('max', 0)}ê°œ")
        
        count_dist = rel.get("professors_by_patent_count", {})
        print(f"   - íŠ¹í—ˆ ê°œìˆ˜ë³„ êµìˆ˜ ë¶„í¬:")
        for range_str, count in count_dist.items():
            print(f"     * {range_str}: {count:,}ëª…")
        
        print(f"\n   - ëŒ€í•™ë³„ êµìˆ˜ ìˆ˜:")
        for college, count in list(rel.get("college_distribution", {}).items())[:5]:
            print(f"     * {college}: {count:,}ëª…")
        
        print(f"\n   - í•™ê³¼ë³„ êµìˆ˜ ìˆ˜:")
        for dept, count in list(rel.get("department_distribution", {}).items())[:5]:
            print(f"     * {dept}: {count:,}ëª…")
    
    # íŠ¹í—ˆ ìƒíƒœ
    if "patent_status" in results:
        status = results["patent_status"]
        print(f"\n3ï¸âƒ£  íŠ¹í—ˆ ìƒíƒœ ë¶„ì„")
        overall = status.get("overall_status_distribution", {})
        for stat, count in sorted(overall.items(), key=lambda x: x[1], reverse=True):
            print(f"   - {stat}: {count:,}ê°œ")
    
    # ì—°ë„ë³„ ì¶”ì´
    if "timeline" in results:
        timeline = results["timeline"]
        year_dist = timeline.get("year_distribution", {})
        if year_dist:
            print(f"\n4ï¸âƒ£  ì—°ë„ë³„ ì¶œì› ì¶”ì´")
            recent_years = list(sorted(year_dist.items(), reverse=True))[:5]
            for year, count in recent_years:
                prof_count = timeline.get("professors_per_year", {}).get(year, 0)
                print(f"   - {year}ë…„: {count:,}ê°œ (êµìˆ˜ {prof_count:,}ëª…)")
    
    # ëŒ€í•™/í•™ê³¼ë³„ íŠ¹í—ˆ
    if "college_department" in results:
        cd = results["college_department"]
        print(f"\n5ï¸âƒ£  ëŒ€í•™/í•™ê³¼ë³„ íŠ¹í—ˆ ë¶„í¬ (êµìˆ˜-íŠ¹í—ˆ ë§¤í•‘)")
        print(f"   - ìƒìœ„ ëŒ€í•™ (íŠ¹í—ˆ ìˆ˜):")
        for college, count in cd.get("top_colleges", [])[:5]:
            prof_count = cd.get("college_professor_count", {}).get(college, 0)
            avg_patents = cd.get("college_avg_patents_per_professor", {}).get(college, 0)
            print(f"     * {college}: {count:,}ê°œ (êµìˆ˜ {prof_count}ëª…, êµìˆ˜ë‹¹ í‰ê·  {avg_patents:.2f}ê°œ)")
        print(f"   - ìƒìœ„ í•™ê³¼ (íŠ¹í—ˆ ìˆ˜):")
        for dept, count in cd.get("top_departments", [])[:5]:
            prof_count = cd.get("department_professor_count", {}).get(dept, 0)
            print(f"     * {dept}: {count:,}ê°œ (êµìˆ˜ {prof_count}ëª…)")
        print(f"   - êµìˆ˜ë‹¹ í‰ê·  íŠ¹í—ˆìˆ˜ ìƒìœ„ ë‹¨ê³¼ëŒ€:")
        for college, avg in cd.get("top_colleges_by_avg_patents", [])[:5]:
            total = cd.get("college_patent_distribution", {}).get(college, 0)
            prof_count = cd.get("college_professor_count", {}).get(college, 0)
            print(f"     * {college}: êµìˆ˜ë‹¹ í‰ê·  {avg:.2f}ê°œ (ì´ {total}ê°œ, êµìˆ˜ {prof_count}ëª…)")
    
    # íŠ¹í—ˆ ë‚´ìš©
    if "content" in results:
        content = results["content"]
        print(f"\n6ï¸âƒ£  íŠ¹í—ˆ ë‚´ìš© ë¶„ì„")
        titles = content.get("titles", {})
        abstracts = content.get("abstracts", {})
        print(f"   - ì œëª©: {titles.get('total', 0):,}ê°œ")
        if titles.get("length_stats"):
            print(f"     í‰ê·  ê¸¸ì´: {titles['length_stats'].get('mean', 0):.1f}ì")
        print(f"   - ìš”ì•½: {abstracts.get('total', 0):,}ê°œ")
        if abstracts.get("length_stats"):
            print(f"     í‰ê·  ê¸¸ì´: {abstracts['length_stats'].get('mean', 0):.1f}ì")
    
    # ì´ˆë¡ ìƒì„¸ ë¶„ì„
    if "abstract_detailed" in results:
        abs_detail = results["abstract_detailed"]
        if "error" not in abs_detail:
            print(f"\n8ï¸âƒ£  ì´ˆë¡(Abstract) ìƒì„¸ ë¶„ì„")
            print(f"   - ì´ ë°ì´í„°: {abs_detail.get('total_items', 0):,}ê°œ")
            print(f"   - ìœ íš¨ ì´ˆë¡: {abs_detail.get('valid_count', 0):,}ê°œ ({abs_detail.get('valid_rate', 0)}%)")
            print(f"   - ê²°ì¸¡ì¹˜: {abs_detail.get('missing_count', 0):,}ê°œ ({abs_detail.get('missing_rate', 0)}%)")
            
            stats = abs_detail.get("descriptive_statistics", {})
            if stats:
                print(f"\n   - ê¸°ìˆ  í†µê³„ëŸ‰:")
                print(f"     * ìµœì†Œê°’: {stats.get('min', 0):,}ì")
                print(f"     * ìµœëŒ€ê°’: {stats.get('max', 0):,}ì")
                print(f"     * í‰ê· : {stats.get('mean', 0):.2f}ì")
                print(f"     * ì¤‘ì•™ê°’ (Q2): {stats.get('median', 0):,}ì")
                print(f"     * í‘œì¤€í¸ì°¨: {stats.get('std', 0):.2f}ì")
                print(f"\n   - 4ë¶„ìœ„ìˆ˜:")
                print(f"     * Q1 (1ì‚¬ë¶„ìœ„ìˆ˜): {stats.get('q1', 0):,}ì")
                print(f"     * Q2 (2ì‚¬ë¶„ìœ„ìˆ˜, ì¤‘ì•™ê°’): {stats.get('q2', 0):,}ì")
                print(f"     * Q3 (3ì‚¬ë¶„ìœ„ìˆ˜): {stats.get('q3', 0):,}ì")
                print(f"     * IQR (ì‚¬ë¶„ìœ„ ë²”ìœ„): {stats.get('iqr', 0):,}ì")
            
            quartile = abs_detail.get("quartile_distribution", {})
            if quartile:
                print(f"\n   - 4ë¶„ìœ„ìˆ˜ë³„ ë¶„í¬:")
                print(f"     * Q1 ì´í•˜: {quartile.get('q1_under', 0):,}ê°œ")
                print(f"     * Q1~Q2: {quartile.get('q1_to_q2', 0):,}ê°œ")
                print(f"     * Q2~Q3: {quartile.get('q2_to_q3', 0):,}ê°œ")
                print(f"     * Q3 ì´ˆê³¼: {quartile.get('q3_over', 0):,}ê°œ")
    
    # êµìˆ˜ ì •ë³´ ì™„ì „ì„±
    if "professor_completeness" in results:
        comp = results["professor_completeness"]
        print(f"\n7ï¸âƒ£  êµìˆ˜ ì •ë³´ ì™„ì „ì„±")
        print(f"   - êµìˆ˜ ì •ë³´ê°€ ìˆëŠ” íŠ¹í—ˆ: {comp.get('total_with_professor_info', 0):,}ê°œ")
        print(f"   - ê°€ì¥ ì™„ì „í•œ í•„ë“œ:")
        for field, rate in comp.get("most_complete_fields", [])[:3]:
            print(f"     * {field}: {rate:.1f}%")
    
    print("\n" + "=" * 70)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” íŠ¹í—ˆ ë°ì´í„° EDA ì‹œì‘ (êµìˆ˜-íŠ¹í—ˆ ê´€ê³„ ì¤‘ì‹¬)...")
    
    # ë°ì´í„° ë¡œë“œ
    data = load_patent_data(PATENT_DATA_FILE)
    
    if not data:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¶„ì„ ìˆ˜í–‰
    results = {
        "basic_info": analyze_basic_info(data),
        "professor_patent_relationship": analyze_professor_patent_relationship(data),
        "patent_status": analyze_patent_status_by_professor(data),
        "timeline": analyze_patent_timeline(data),
        "content": analyze_patent_content(data),
        "professor_completeness": analyze_professor_info_completeness(data),
        "college_department": analyze_college_department_patents(data),
        "abstract_detailed": analyze_abstract_detailed(data)
    }
    
    # ê²°ê³¼ ì¶œë ¥
    print_summary(results)
    
    # ê²°ê³¼ ì €ì¥
    output_path = Path(EDA_RESULTS_DIR) / "patent_eda_results.json"
    save_results(results, output_path)
    
    # ì´ˆë¡ ë¶„í¬ ì‹œê°í™”
    visualize_abstract_distribution(data, Path(EDA_RESULTS_DIR))


if __name__ == "__main__":
    main()
